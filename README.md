```markdown
# Branding-Blends

## Branding_Blends_Backend

肌状態と髪の清潔感をAIで自動評価するWebアプリのバックエンドです。  
ユーザーがアップロードした顔画像から、AIが3つの観点（肌、髪、髭）をスコアリングし、結果を返却・保存します。  
こちらのフロントエンドと接続します。  
👉 https://github.com/showheysas/BBB-Frontend

---

## 🧠 このプロジェクトでやっていること

### 1. 学習済みモデルの活用

本アプリは、PyTorchで学習した以下の分類モデルを活用しています：

| モデル                      | 分類内容                         | 使用手法                         | 備考                                |
|-----------------------------|----------------------------------|----------------------------------|-------------------------------------|
| Skin Classifier             | 肌質（乾燥肌・脂性肌・普通肌）     | CNN（畳み込みニューラルネットワーク） | データ拡張あり                     |
| Hair Cleanliness Classifier | 髪の清潔感（清潔 / 非清潔）       | 転移学習（ResNet18）              | データ不均衡に対応、交差検証あり   |

モデル学習は、FastAPIのプロジェクトとは別のローカルリポジトリで行い、`pth` (PyTorch)形式のファイルを出力しています。  
これらのモデルは `.pth` ファイルとして `backend/models/` に保存されており、FastAPI のエンドポイントに組み込まれています。

---

## 🧬 CNN学習モデルの構築と活用フロー（初心者向け解説）

### 💡 このAIモデルでやっていること

顔写真をもとに、肌タイプ（オイリー／乾燥／ノーマル）や髪の清潔感を自動で判定します。  
画像のパターンを見て判断するAI＝CNN（畳み込みニューラルネットワーク）を使用しています。

---

### 📦 肌分類モデル（SkinClassifierCNN）の学習フロー

#### 1. データ準備
- 「オイリー肌」「乾燥肌」「普通肌」とラベル付けされた顔画像を収集

#### 2. データ拡張・前処理
- 画像サイズを224x224に統一
- 回転、反転、明るさ変更などを行い、画像パターンのバリエーションを増やして学習効率と精度向上を図る
- 画素値の正規化も実施

#### 3. CNN構築（オリジナルモデル）
- 複数の畳み込み層・プーリング層・全結合層で構成
- 画像の特徴（色、テカリ、模様など）を段階的に抽出し、最終的に肌タイプを分類

```
class SkinClassifierCNN(nn.Module):
    def __init__(self):
        conv1 → conv2 → conv3 → pool → fc1 → fc2
```

#### 4. 学習ループ（エポックについて）
- 訓練データ全体を1回学習するサイクルを「エポック」と呼びます
- 1エポックごとに、全データを使ってモデルのパラメータを更新
- 20エポック繰り返し、モデルを少しずつ賢くしていきます
- 各エポックごとに未使用の検証データで精度をチェックし、過学習を防ぎます

#### 5. モデル保存
- 学習済みモデルを`.pth`形式で保存し、FastAPIからすぐに呼び出せるようにします

---

### 💇‍♂️ 髪の清潔感分類モデル（Hair Cleanliness Classifier）の学習フロー

髪の清潔感を判定するAIモデルは、**転移学習**と**強力なデータ拡張**、**クラス不均衡対策**、**交差検証**など、より実践的な機械学習手法を取り入れています。

#### 1. データ準備と前処理

- 髪の清潔感が「清潔」または「非清潔」とラベル付けされた画像を用意します。
- ランダムクロップ・リサイズ、反転、回転、色調補正、パースペクティブ変形、ガウシアンブラーなどアグレッシブなデータ拡張を実施し、さまざまな髪型や環境に対応できるようにします。

#### 2. クラス不均衡対策

- 「清潔」「非清潔」の画像枚数が偏っている場合、クラスごとの重みを自動計算し、損失関数やサンプリングに反映します。
- 少数派クラスも正しく学習できるようにしています。

#### 3. モデル構築：転移学習（ResNet18）

- ResNet18（ImageNetで事前学習済み）をベースに、髪の清潔感判定用にカスタマイズ。
- 既存の特徴抽出層はフリーズし、最後の全結合層のみ再学習。
- 最終層は2クラス（清潔/非清潔）分類用に再設計し、ドロップアウトも追加して過学習を防止。

#### 4. 5分割交差検証（KFold Cross Validation）

- データセットを5分割し、各フォールドで訓練・検証を繰り返します。
- データの偏りに左右されにくい、信頼性の高いモデル評価が可能です。

#### 5. 学習ループと工夫

- 損失関数：クラス重み付きクロスエントロピー
- 最適化：Adam（L2正則化付き）
- 学習率スケジューラ：検証損失が下がらなくなったら自動で学習率を減少
- アーリーストッピング：検証損失が改善しない場合は早めに学習を打ち切り、最良モデルを保存
- 最大50エポックまで繰り返し学習（早期終了あり）、バッチサイズは16

#### 6. 評価と可視化

- 各フォールドごとに検証精度を記録し、最終的に平均精度と標準偏差を算出。
- 学習曲線（損失と精度）もグラフで可視化し、モデルの学習状況を確認。

---

### 🏗️ CNNの構成（詳細解説）

CNN（畳み込みニューラルネットワーク）は、以下のような層で構成されます：

- **畳み込み層（Convolutional Layer）**  
  画像から特徴（エッジや模様など）を抽出する層。複数のフィルターで画像のパターンを検出します。

- **活性化関数（ReLUなど）**  
  非線形変換を加え、より複雑なパターンを学習できるようにします。

- **プーリング層（Pooling Layer）**  
  特徴マップのサイズを縮小し、重要な特徴だけを残します。位置ずれにも強くなります。

- **全結合層（Fully Connected Layer）**  
  抽出した特徴をもとに最終的な分類を行います。

- **出力層**  
  クラスごとの確率を出力し、最も高い確率のクラスを予測として返します。

この階層構造により、画像の複雑な特徴を段階的に抽出し、自動で分類できるようになります。

---

### 🔧 FastAPIでの推論エンドポイント

ユーザーの顔画像を受け取り、以下の処理を行う `/upload` エンドポイントを提供しています：

1. 顔領域の検出・クロッピング（`face_recognition` 使用）
2. 学習済みモデルによる肌・髪の分類
3. 髭は現状ダミースコア（80点）を返す仕様
4. 各スコアと合計スコアの計算
5. 画像とスコアをDBに保存（SQLAlchemy）

レスポンスとして、`transaction_id` を返します。

---

### 🔑 認証エンドポイント (`auth.py`)

#### 1. ユーザー登録
- **エンドポイント**: `/register`
- **説明**: 新規ユーザーを登録します。
- **リクエスト**: ユーザー情報 (`user_id`, `password`, `name`) を送信。
- **レスポンス**: 登録成功メッセージと `user_id` を返却。

#### 2. ログイン
- **エンドポイント**: `/login`
- **説明**: 登録済みユーザーがログインし、アクセストークンを取得します。
- **リクエスト**: ユーザーIDとパスワード。
- **レスポンス**: JWT形式のアクセストークン。

#### 3. 保護されたルート
- **エンドポイント**: `/protected`
- **説明**: トークン検証後にアクセス可能な保護されたルート。
- **リクエスト**: Authorizationヘッダーにトークンを含めて送信。
- **レスポンス**: 認証成功メッセージ。

---

### 📊 結果取得エンドポイント (`result.py`)

#### 1. 結果取得
- **エンドポイント**: `/{transaction_id}`
- **説明**: 特定のトランザクションIDに基づいて評価結果を取得します。
- **リクエスト**: トランザクションIDと認証トークン。
- **レスポンス**:
  - 各項目（肌状態、髪状態、髭状態）のスコア（10点満点および100点満点）。
  - スコアに基づいたコメント。
  - トータルスコアとそのコメント。

#### コメント生成
スコアに応じて以下のようなコメントがランダムに生成されます：
- **90点以上**: 素晴らしい状態です！理想的なコンディションです！
- **75点以上**: 良好な状態です。この調子で頑張りましょう！
- **それ以下**: 改善の余地があります。一緒に頑張りましょう！

---

### 🔧 ディレクトリ構成と主な役割

```
backend/
├── app/               # FastAPI本体のコード群
│   ├── api/           # APIエンドポイント定義（upload, result, auth）
│   ├── core/          # アプリの設定や認証処理（JWT検証など）
│   ├── db/            # DB接続・モデル定義・CRUD操作
│   ├── schemas/       # Pydanticによるリクエスト/レスポンス定義
│   └── main.py        # FastAPI起動スクリプト（エントリーポイント）
│
├── models/            # 学習済みモデルの保存場所（.pthファイル）　※GitHub未連携
│   ├── skin_classifier_model.pth
│   ├── hair_classifier_cleanliness.pth
│   └── beard_classifier.pth（※未使用）
│
├── requirements.txt   # 使用ライブラリ一覧
└── .env               # 環境変数（APIキーやDB接続文字列など）
```

---

### 🌟 FaceRecognitionとOpenCVによる画像処理

#### 顔領域検出と前処理
- 顔画像はOpenCVとFaceRecognitionライブラリで処理されます。
- 顔領域拡張後に切り取り・リサイズし、PIL形式で正規化処理。

---

### 📚 ディープラーニングの全体像とエポックの解説

#### ディープラーニングの流れ（本プロジェクトの例）

1. **データ準備**  
   画像データを集め、ラベル付けを行います。

2. **前処理・データ拡張**  
   画像サイズを統一し、回転・反転・色調補正などでデータを増やします。

3. **モデル構築（CNNや転移学習モデル）**  
   畳み込み層・プーリング層・全結合層などを組み合わせ、画像の特徴を自動で抽出・分類します。

4. **学習（トレーニング）**  
   損失関数と最適化アルゴリズムを使い、モデルのパラメータをデータに合わせて調整します。

5. **評価（バリデーション）**  
   未使用の検証データで、モデルの精度や汎用性を確認します。

6. **モデル保存・活用**  
   学習済みモデルを保存し、APIから呼び出して推論に利用します。

#### エポック（Epoch）とは？

- **エポック**は「訓練データ全体を1回、モデルに学習させるサイクル」のことです。
- 1エポックごとに、すべての訓練データを使ってモデルを改善します。
- 通常は複数エポック（例：20回や50回）繰り返して学習を深めます。
- エポック数が多すぎると過学習のリスクがあるため、適切な値を選びます。

---

### 📌 備考

- `beard_classifier.pth` は現時点で未使用です（今後拡張予定）。
- 顔検出には dlib ベースの `face_recognition` を利用しています。

---
```